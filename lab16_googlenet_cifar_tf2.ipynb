{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab16_googlenet_cifar_tf2.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jwkanggist/EverybodyTensorflow2.0/blob/master/lab16_googlenet_cifar_tf2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRFuS_UpsuIE",
        "colab_type": "text"
      },
      "source": [
        "#LAB16: GoogLenet for imagenet\n",
        "\n",
        "Inception을 구현하여 GoogLenet을 구현해보자 \n",
        "- ImageNet datatset을 위한 실험\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eqAsq9nsp0P",
        "colab_type": "code",
        "outputId": "6c997973-18a1-43c4-d0bc-6deb7511ab77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# preprocessor parts\n",
        "\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "# Install TensorFlow\n",
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "from matplotlib import cm\n",
        "from matplotlib import gridspec\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from datetime import datetime"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ES0hIsUdZMRc",
        "colab_type": "code",
        "outputId": "394ea064-9d4f-4547-f761-3219582ba4c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "  # for Tensorboard use\n",
        "  LOG_DIR = 'drive/data/tb_logs'\n",
        "\t\n",
        "  !wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "  !unzip ngrok-stable-linux-amd64.zip\n",
        "\t\n",
        "  import os\n",
        "  if not os.path.exists(LOG_DIR):\n",
        "    os.makedirs(LOG_DIR)\n",
        "\t  \n",
        "  get_ipython().system_raw(\n",
        "      'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "      .format(LOG_DIR))\n",
        "\t\n",
        "  get_ipython().system_raw('./ngrok http 6006 &')\n",
        "\t\n",
        "  !curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "      \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-16 16:24:38--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 52.206.168.246, 52.204.223.154, 34.193.139.214, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|52.206.168.246|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13773305 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "\r          ngrok-sta   0%[                    ]       0  --.-KB/s               \r         ngrok-stab  32%[=====>              ]   4.31M  21.5MB/s               \r        ngrok-stabl  80%[===============>    ]  10.57M  26.4MB/s               \rngrok-stable-linux- 100%[===================>]  13.13M  28.2MB/s    in 0.5s    \n",
            "\n",
            "2020-01-16 16:24:39 (28.2 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13773305/13773305]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n",
            "https://517ac59f.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZR5Lp-Xs5OS",
        "colab_type": "code",
        "outputId": "8689b242-9239-4fc6-c811-23c783a8fa00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# dataset loading part\n",
        "# 데이터 파이프라인 부분 \n",
        "\n",
        "cifar100 = tf.keras.datasets.cifar100\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "print(\"x_train.shape = %s\" % str(x_train.shape))\n",
        "print(\"y_train.shape = %s\" % str(x_train.shape))\n",
        "\n",
        "x_train = x_train.reshape([x_train.shape[0],\n",
        "                           x_train.shape[1],\n",
        "                           x_train.shape[2],3])\n",
        "\n",
        "x_test = x_test.reshape([x_test.shape[0],\n",
        "                           x_test.shape[1],\n",
        "                           x_test.shape[2],3])\n",
        "\n",
        "\n",
        "x_train = np.array(tf.keras.backend.resize_images(x_train, height_factor=2,width_factor=2, data_format='channels_last',interpolation='bilinear'))\n",
        "x_test = np.array(tf.keras.backend.resize_images(x_test, height_factor=2,width_factor=2, data_format='channels_last',interpolation='bilinear'))\n",
        "\n",
        "print(\"x_train.shape = %s\" % str(x_train.shape))\n",
        "print(\"x_test.shape = %s\" % str(x_test.shape))\n",
        "\n",
        "print(\"y_train.shape = %s\" % str(y_train.shape))\n",
        "print(\"y_test.shape = %s\" % str(y_test.shape))\n",
        "\n",
        "input_shape = x_train.shape[1]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n",
            "169009152/169001437 [==============================] - 2s 0us/step\n",
            "x_train.shape = (50000, 32, 32, 3)\n",
            "y_train.shape = (50000, 32, 32, 3)\n",
            "x_train.shape = (50000, 64, 64, 3)\n",
            "x_test.shape = (10000, 64, 64, 3)\n",
            "y_train.shape = (50000, 1)\n",
            "y_test.shape = (10000, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXOTDGtts570",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Network modules\n",
        "def conv_batchnorm_relu(net_in,filters,kernel_size,strides):\n",
        "  net = tf.keras.layers.Conv2D(filters,kernel_size=(kernel_size,kernel_size),\n",
        "                               strides=(strides,strides),\n",
        "                               padding='same',\n",
        "                               kernel_initializer='he_normal',\n",
        "                               activation=None)(net_in)\n",
        "  net = tf.keras.layers.BatchNormalization()(net)\n",
        "  net = tf.keras.layers.Activation(activation='relu')(net)\n",
        "  return net\n",
        "\n",
        "\n",
        "def reduced_conv(net_in,reduced_chdim,filters,kernel_size,strides):\n",
        "  net = conv_batchnorm_relu(net_in,reduced_chdim,1,1)\n",
        "  net = conv_batchnorm_relu(net,filters,kernel_size,strides)\n",
        "  return net\n",
        "\n",
        "\n",
        "def inception(net_in,chdim1x1,chdim3x3reduce,chdim3x3,chdim5x5reduce,chdim5x5,maxproj,name):\n",
        "  with tf.keras.backend.name_scope(name):\n",
        "    net1  = conv_batchnorm_relu(net_in,filters=chdim1x1,\n",
        "                                kernel_size=1,\n",
        "                                strides=1)\n",
        "    net2 = reduced_conv(net_in,chdim3x3reduce,chdim3x3,kernel_size=3,strides=1)\n",
        "    net3 = reduced_conv(net_in,chdim5x5reduce,chdim5x5,kernel_size=5,strides=1)\n",
        "    net4 = tf.keras.layers.MaxPool2D(pool_size=(3,3),strides=(1,1),padding='same')(net_in)\n",
        "    net4 = conv_batchnorm_relu(net4,maxproj,1,1)\n",
        "    net = tf.keras.layers.concatenate([net1,net2,net3,net4],axis=3)\n",
        "  return net\n",
        "\n",
        "# googlenet model\n",
        "net_in = tf.keras.layers.Input(shape=(input_shape,input_shape,3))\n",
        "net = tf.keras.layers.Conv2D(64,kernel_size=(9,9),strides=1,padding='valid', kernel_initializer='he_normal',activation='relu')(net_in)\n",
        "net = conv_batchnorm_relu(net,filters=192,kernel_size=3,strides=1)\n",
        "net = inception(net,64,96,128,16,32,32,name='inception3a')  \n",
        "net = inception(net,128,128,192,32,96,64,name='inception4b')\n",
        "net = tf.keras.layers.MaxPool2D(pool_size=[3,3],strides=2)(net)\n",
        "net = inception(net,192,96,208,16,48,64,name='inception4a')\n",
        "net = inception(net,160,112,224,24,64,64,name='inception4b')\n",
        "net = inception(net,128,128,256,24,64,64,name='inception4c')  \n",
        "net = inception(net,112,144,288,32,64,64,name='inception4d')\n",
        "net = inception(net,256,160,320,32,128,128,name='inceptioin4e')\n",
        "net = tf.keras.layers.MaxPool2D(pool_size=[3,3],strides=2)(net)\n",
        "net = inception(net,256,160,320,32,128,128,name='inception5a')\n",
        "net = inception(net,384,192,384,48,128,128,name='inception5b')\n",
        "net = tf.keras.layers.GlobalAvgPool2D(data_format='channels_last')(net)\n",
        "net = tf.keras.layers.Dropout(0.4)(net)\n",
        "net = tf.keras.layers.Dense(units=1000,activation='softmax')(net)\n",
        "\n",
        "model = tf.keras.models.Model(inputs=net_in,outputs=net)\n",
        "\n",
        "\n",
        "opt_fn = tf.keras.optimizers.Adam(learning_rate=1e-3,\n",
        "                                beta_1=0.9,\n",
        "                                beta_2=0.999)\n",
        "\n",
        "# 'sparse_categorical_crossentropy' is for integer labels\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "tensorboard_callback = TensorBoard(log_dir=LOG_DIR, \n",
        "                           histogram_freq=1,\n",
        "                           write_graph=True,\n",
        "                           write_images=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IAXZUvis6Wq",
        "colab_type": "code",
        "outputId": "fe50f447-f6a0-433d-8ae8-bf7d38aeece7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# model training and evaluation part\n",
        "training_epochs = 20\n",
        "batch_size = 128\n",
        "model.summary()\n",
        "model.fit(x_train, y_train, \n",
        "          epochs=training_epochs,\n",
        "          validation_data=(x_test, y_test),\n",
        "          batch_size=batch_size,\n",
        "          callbacks=[tensorboard_callback])\n",
        "model.evaluate(x_test,  y_test, verbose=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_7\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_15 (InputLayer)           [(None, 64, 64, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_490 (Conv2D)             (None, 56, 56, 64)   15616       input_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_491 (Conv2D)             (None, 56, 56, 192)  110784      conv2d_490[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_476 (BatchN (None, 56, 56, 192)  768         conv2d_491[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_476 (Activation)     (None, 56, 56, 192)  0           batch_normalization_476[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_493 (Conv2D)             (None, 56, 56, 96)   18528       activation_476[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_495 (Conv2D)             (None, 56, 56, 16)   3088        activation_476[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_478 (BatchN (None, 56, 56, 96)   384         conv2d_493[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_480 (BatchN (None, 56, 56, 16)   64          conv2d_495[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_478 (Activation)     (None, 56, 56, 96)   0           batch_normalization_478[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_480 (Activation)     (None, 56, 56, 16)   0           batch_normalization_480[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_93 (MaxPooling2D) (None, 56, 56, 192)  0           activation_476[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_492 (Conv2D)             (None, 56, 56, 64)   12352       activation_476[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_494 (Conv2D)             (None, 56, 56, 128)  110720      activation_478[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_496 (Conv2D)             (None, 56, 56, 32)   12832       activation_480[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_497 (Conv2D)             (None, 56, 56, 32)   6176        max_pooling2d_93[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_477 (BatchN (None, 56, 56, 64)   256         conv2d_492[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_479 (BatchN (None, 56, 56, 128)  512         conv2d_494[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_481 (BatchN (None, 56, 56, 32)   128         conv2d_496[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_482 (BatchN (None, 56, 56, 32)   128         conv2d_497[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_477 (Activation)     (None, 56, 56, 64)   0           batch_normalization_477[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_479 (Activation)     (None, 56, 56, 128)  0           batch_normalization_479[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_481 (Activation)     (None, 56, 56, 32)   0           batch_normalization_481[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_482 (Activation)     (None, 56, 56, 32)   0           batch_normalization_482[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_77 (Concatenate)    (None, 56, 56, 256)  0           activation_477[0][0]             \n",
            "                                                                 activation_479[0][0]             \n",
            "                                                                 activation_481[0][0]             \n",
            "                                                                 activation_482[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_499 (Conv2D)             (None, 56, 56, 128)  32896       concatenate_77[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_501 (Conv2D)             (None, 56, 56, 32)   8224        concatenate_77[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_484 (BatchN (None, 56, 56, 128)  512         conv2d_499[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_486 (BatchN (None, 56, 56, 32)   128         conv2d_501[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_484 (Activation)     (None, 56, 56, 128)  0           batch_normalization_484[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_486 (Activation)     (None, 56, 56, 32)   0           batch_normalization_486[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_94 (MaxPooling2D) (None, 56, 56, 256)  0           concatenate_77[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_498 (Conv2D)             (None, 56, 56, 128)  32896       concatenate_77[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_500 (Conv2D)             (None, 56, 56, 192)  221376      activation_484[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_502 (Conv2D)             (None, 56, 56, 96)   76896       activation_486[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_503 (Conv2D)             (None, 56, 56, 64)   16448       max_pooling2d_94[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_483 (BatchN (None, 56, 56, 128)  512         conv2d_498[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_485 (BatchN (None, 56, 56, 192)  768         conv2d_500[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_487 (BatchN (None, 56, 56, 96)   384         conv2d_502[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_488 (BatchN (None, 56, 56, 64)   256         conv2d_503[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_483 (Activation)     (None, 56, 56, 128)  0           batch_normalization_483[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_485 (Activation)     (None, 56, 56, 192)  0           batch_normalization_485[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_487 (Activation)     (None, 56, 56, 96)   0           batch_normalization_487[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_488 (Activation)     (None, 56, 56, 64)   0           batch_normalization_488[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_78 (Concatenate)    (None, 56, 56, 480)  0           activation_483[0][0]             \n",
            "                                                                 activation_485[0][0]             \n",
            "                                                                 activation_487[0][0]             \n",
            "                                                                 activation_488[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_95 (MaxPooling2D) (None, 27, 27, 480)  0           concatenate_78[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_505 (Conv2D)             (None, 27, 27, 96)   46176       max_pooling2d_95[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_507 (Conv2D)             (None, 27, 27, 16)   7696        max_pooling2d_95[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_490 (BatchN (None, 27, 27, 96)   384         conv2d_505[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_492 (BatchN (None, 27, 27, 16)   64          conv2d_507[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_490 (Activation)     (None, 27, 27, 96)   0           batch_normalization_490[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_492 (Activation)     (None, 27, 27, 16)   0           batch_normalization_492[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_96 (MaxPooling2D) (None, 27, 27, 480)  0           max_pooling2d_95[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_504 (Conv2D)             (None, 27, 27, 192)  92352       max_pooling2d_95[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_506 (Conv2D)             (None, 27, 27, 208)  179920      activation_490[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_508 (Conv2D)             (None, 27, 27, 48)   19248       activation_492[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_509 (Conv2D)             (None, 27, 27, 64)   30784       max_pooling2d_96[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_489 (BatchN (None, 27, 27, 192)  768         conv2d_504[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_491 (BatchN (None, 27, 27, 208)  832         conv2d_506[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_493 (BatchN (None, 27, 27, 48)   192         conv2d_508[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_494 (BatchN (None, 27, 27, 64)   256         conv2d_509[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_489 (Activation)     (None, 27, 27, 192)  0           batch_normalization_489[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_491 (Activation)     (None, 27, 27, 208)  0           batch_normalization_491[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_493 (Activation)     (None, 27, 27, 48)   0           batch_normalization_493[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_494 (Activation)     (None, 27, 27, 64)   0           batch_normalization_494[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_79 (Concatenate)    (None, 27, 27, 512)  0           activation_489[0][0]             \n",
            "                                                                 activation_491[0][0]             \n",
            "                                                                 activation_493[0][0]             \n",
            "                                                                 activation_494[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_511 (Conv2D)             (None, 27, 27, 112)  57456       concatenate_79[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_513 (Conv2D)             (None, 27, 27, 24)   12312       concatenate_79[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_496 (BatchN (None, 27, 27, 112)  448         conv2d_511[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_498 (BatchN (None, 27, 27, 24)   96          conv2d_513[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_496 (Activation)     (None, 27, 27, 112)  0           batch_normalization_496[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_498 (Activation)     (None, 27, 27, 24)   0           batch_normalization_498[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_97 (MaxPooling2D) (None, 27, 27, 512)  0           concatenate_79[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_510 (Conv2D)             (None, 27, 27, 160)  82080       concatenate_79[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_512 (Conv2D)             (None, 27, 27, 224)  226016      activation_496[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_514 (Conv2D)             (None, 27, 27, 64)   38464       activation_498[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_515 (Conv2D)             (None, 27, 27, 64)   32832       max_pooling2d_97[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_495 (BatchN (None, 27, 27, 160)  640         conv2d_510[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_497 (BatchN (None, 27, 27, 224)  896         conv2d_512[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_499 (BatchN (None, 27, 27, 64)   256         conv2d_514[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_500 (BatchN (None, 27, 27, 64)   256         conv2d_515[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_495 (Activation)     (None, 27, 27, 160)  0           batch_normalization_495[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_497 (Activation)     (None, 27, 27, 224)  0           batch_normalization_497[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_499 (Activation)     (None, 27, 27, 64)   0           batch_normalization_499[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_500 (Activation)     (None, 27, 27, 64)   0           batch_normalization_500[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_80 (Concatenate)    (None, 27, 27, 512)  0           activation_495[0][0]             \n",
            "                                                                 activation_497[0][0]             \n",
            "                                                                 activation_499[0][0]             \n",
            "                                                                 activation_500[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_517 (Conv2D)             (None, 27, 27, 128)  65664       concatenate_80[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_519 (Conv2D)             (None, 27, 27, 24)   12312       concatenate_80[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_502 (BatchN (None, 27, 27, 128)  512         conv2d_517[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_504 (BatchN (None, 27, 27, 24)   96          conv2d_519[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_502 (Activation)     (None, 27, 27, 128)  0           batch_normalization_502[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_504 (Activation)     (None, 27, 27, 24)   0           batch_normalization_504[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_98 (MaxPooling2D) (None, 27, 27, 512)  0           concatenate_80[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_516 (Conv2D)             (None, 27, 27, 128)  65664       concatenate_80[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_518 (Conv2D)             (None, 27, 27, 256)  295168      activation_502[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_520 (Conv2D)             (None, 27, 27, 64)   38464       activation_504[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_521 (Conv2D)             (None, 27, 27, 64)   32832       max_pooling2d_98[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_501 (BatchN (None, 27, 27, 128)  512         conv2d_516[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_503 (BatchN (None, 27, 27, 256)  1024        conv2d_518[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_505 (BatchN (None, 27, 27, 64)   256         conv2d_520[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_506 (BatchN (None, 27, 27, 64)   256         conv2d_521[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_501 (Activation)     (None, 27, 27, 128)  0           batch_normalization_501[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_503 (Activation)     (None, 27, 27, 256)  0           batch_normalization_503[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_505 (Activation)     (None, 27, 27, 64)   0           batch_normalization_505[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_506 (Activation)     (None, 27, 27, 64)   0           batch_normalization_506[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_81 (Concatenate)    (None, 27, 27, 512)  0           activation_501[0][0]             \n",
            "                                                                 activation_503[0][0]             \n",
            "                                                                 activation_505[0][0]             \n",
            "                                                                 activation_506[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_523 (Conv2D)             (None, 27, 27, 144)  73872       concatenate_81[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_525 (Conv2D)             (None, 27, 27, 32)   16416       concatenate_81[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_508 (BatchN (None, 27, 27, 144)  576         conv2d_523[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_510 (BatchN (None, 27, 27, 32)   128         conv2d_525[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_508 (Activation)     (None, 27, 27, 144)  0           batch_normalization_508[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_510 (Activation)     (None, 27, 27, 32)   0           batch_normalization_510[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_99 (MaxPooling2D) (None, 27, 27, 512)  0           concatenate_81[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_522 (Conv2D)             (None, 27, 27, 112)  57456       concatenate_81[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_524 (Conv2D)             (None, 27, 27, 288)  373536      activation_508[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_526 (Conv2D)             (None, 27, 27, 64)   51264       activation_510[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_527 (Conv2D)             (None, 27, 27, 64)   32832       max_pooling2d_99[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_507 (BatchN (None, 27, 27, 112)  448         conv2d_522[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_509 (BatchN (None, 27, 27, 288)  1152        conv2d_524[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_511 (BatchN (None, 27, 27, 64)   256         conv2d_526[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_512 (BatchN (None, 27, 27, 64)   256         conv2d_527[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_507 (Activation)     (None, 27, 27, 112)  0           batch_normalization_507[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_509 (Activation)     (None, 27, 27, 288)  0           batch_normalization_509[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_511 (Activation)     (None, 27, 27, 64)   0           batch_normalization_511[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_512 (Activation)     (None, 27, 27, 64)   0           batch_normalization_512[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_82 (Concatenate)    (None, 27, 27, 528)  0           activation_507[0][0]             \n",
            "                                                                 activation_509[0][0]             \n",
            "                                                                 activation_511[0][0]             \n",
            "                                                                 activation_512[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_529 (Conv2D)             (None, 27, 27, 160)  84640       concatenate_82[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_531 (Conv2D)             (None, 27, 27, 32)   16928       concatenate_82[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_514 (BatchN (None, 27, 27, 160)  640         conv2d_529[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_516 (BatchN (None, 27, 27, 32)   128         conv2d_531[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_514 (Activation)     (None, 27, 27, 160)  0           batch_normalization_514[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_516 (Activation)     (None, 27, 27, 32)   0           batch_normalization_516[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_100 (MaxPooling2D (None, 27, 27, 528)  0           concatenate_82[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_528 (Conv2D)             (None, 27, 27, 256)  135424      concatenate_82[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_530 (Conv2D)             (None, 27, 27, 320)  461120      activation_514[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_532 (Conv2D)             (None, 27, 27, 128)  102528      activation_516[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_533 (Conv2D)             (None, 27, 27, 128)  67712       max_pooling2d_100[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_513 (BatchN (None, 27, 27, 256)  1024        conv2d_528[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_515 (BatchN (None, 27, 27, 320)  1280        conv2d_530[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_517 (BatchN (None, 27, 27, 128)  512         conv2d_532[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_518 (BatchN (None, 27, 27, 128)  512         conv2d_533[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_513 (Activation)     (None, 27, 27, 256)  0           batch_normalization_513[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_515 (Activation)     (None, 27, 27, 320)  0           batch_normalization_515[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_517 (Activation)     (None, 27, 27, 128)  0           batch_normalization_517[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_518 (Activation)     (None, 27, 27, 128)  0           batch_normalization_518[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_83 (Concatenate)    (None, 27, 27, 832)  0           activation_513[0][0]             \n",
            "                                                                 activation_515[0][0]             \n",
            "                                                                 activation_517[0][0]             \n",
            "                                                                 activation_518[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_101 (MaxPooling2D (None, 13, 13, 832)  0           concatenate_83[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_535 (Conv2D)             (None, 13, 13, 160)  133280      max_pooling2d_101[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_537 (Conv2D)             (None, 13, 13, 32)   26656       max_pooling2d_101[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_520 (BatchN (None, 13, 13, 160)  640         conv2d_535[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_522 (BatchN (None, 13, 13, 32)   128         conv2d_537[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_520 (Activation)     (None, 13, 13, 160)  0           batch_normalization_520[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_522 (Activation)     (None, 13, 13, 32)   0           batch_normalization_522[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_102 (MaxPooling2D (None, 13, 13, 832)  0           max_pooling2d_101[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_534 (Conv2D)             (None, 13, 13, 256)  213248      max_pooling2d_101[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_536 (Conv2D)             (None, 13, 13, 320)  461120      activation_520[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_538 (Conv2D)             (None, 13, 13, 128)  102528      activation_522[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_539 (Conv2D)             (None, 13, 13, 128)  106624      max_pooling2d_102[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_519 (BatchN (None, 13, 13, 256)  1024        conv2d_534[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_521 (BatchN (None, 13, 13, 320)  1280        conv2d_536[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_523 (BatchN (None, 13, 13, 128)  512         conv2d_538[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_524 (BatchN (None, 13, 13, 128)  512         conv2d_539[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_519 (Activation)     (None, 13, 13, 256)  0           batch_normalization_519[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_521 (Activation)     (None, 13, 13, 320)  0           batch_normalization_521[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_523 (Activation)     (None, 13, 13, 128)  0           batch_normalization_523[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_524 (Activation)     (None, 13, 13, 128)  0           batch_normalization_524[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_84 (Concatenate)    (None, 13, 13, 832)  0           activation_519[0][0]             \n",
            "                                                                 activation_521[0][0]             \n",
            "                                                                 activation_523[0][0]             \n",
            "                                                                 activation_524[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_541 (Conv2D)             (None, 13, 13, 192)  159936      concatenate_84[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_543 (Conv2D)             (None, 13, 13, 48)   39984       concatenate_84[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_526 (BatchN (None, 13, 13, 192)  768         conv2d_541[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_528 (BatchN (None, 13, 13, 48)   192         conv2d_543[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_526 (Activation)     (None, 13, 13, 192)  0           batch_normalization_526[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_528 (Activation)     (None, 13, 13, 48)   0           batch_normalization_528[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_103 (MaxPooling2D (None, 13, 13, 832)  0           concatenate_84[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_540 (Conv2D)             (None, 13, 13, 384)  319872      concatenate_84[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_542 (Conv2D)             (None, 13, 13, 384)  663936      activation_526[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_544 (Conv2D)             (None, 13, 13, 128)  153728      activation_528[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_545 (Conv2D)             (None, 13, 13, 128)  106624      max_pooling2d_103[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_525 (BatchN (None, 13, 13, 384)  1536        conv2d_540[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_527 (BatchN (None, 13, 13, 384)  1536        conv2d_542[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_529 (BatchN (None, 13, 13, 128)  512         conv2d_544[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_530 (BatchN (None, 13, 13, 128)  512         conv2d_545[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_525 (Activation)     (None, 13, 13, 384)  0           batch_normalization_525[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_527 (Activation)     (None, 13, 13, 384)  0           batch_normalization_527[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_529 (Activation)     (None, 13, 13, 128)  0           batch_normalization_529[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_530 (Activation)     (None, 13, 13, 128)  0           batch_normalization_530[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_85 (Concatenate)    (None, 13, 13, 1024) 0           activation_525[0][0]             \n",
            "                                                                 activation_527[0][0]             \n",
            "                                                                 activation_529[0][0]             \n",
            "                                                                 activation_530[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d (Globa (None, 1024)         0           concatenate_85[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 1024)         0           global_average_pooling2d[0][0]   \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 1000)         1025000     dropout_7[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 7,029,144\n",
            "Trainable params: 7,014,840\n",
            "Non-trainable params: 14,304\n",
            "__________________________________________________________________________________________________\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/20\n",
            "49920/50000 [============================>.] - ETA: 0s - loss: 3.6412 - accuracy: 0.1434"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Vr6A5y1t1FY",
        "colab_type": "code",
        "outputId": "f4f4905c-c388-4bc5-b832-e23548371747",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        }
      },
      "source": [
        "# prediction \n",
        "\n",
        "test_input = x_test[300,:,:,:]\n",
        "pred_y = model.predict(test_input.reshape([1,64,64,3]))\n",
        "\n",
        "plt.figure(1)\n",
        "plt.imshow(test_input.reshape([64,64,3]))\n",
        "plt.title(\"input\")\n",
        "print(\"model prediction = %s\"% pred_y.argmax())\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model prediction = 33\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}